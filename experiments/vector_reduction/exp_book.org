#+title: Vector Reduction Experiments book
#+author: Henrique Silva
#+email: hcpsilva@inf.ufrgs.br
#+infojs_opt:
#+property: session *R*
#+property: cache yes
#+property: results graphics
#+property: exports both
#+property: tangle yes

It reduces a vector, that's it.

Preliminary library loading:

#+begin_src R :session :results none
library(DoE.base)
library(tidyverse)
options(scipen = 999)
#+end_src

And the partitions intended to be used in this test:

#+name: machines
#+begin_src bash :tangle no :results output :exports results
echo "draco"
#+end_src

And the scheduling of experiments is supposed to happen according to this
script (which is, by the way, surprisingly generic):

#+begin_src bash :shebang "#!/bin/bash" :tangle launch.sh :var PARTITIONS=machines :results none
# the experiment id
EXPERIMENT_ID=$1

# the work (repo) dir
REPO_DIR=$2

if [[ $REPO_DIR != /* ]]; then
    echo "Path to repository is not absolute, please use the absolute path..."
    exit
fi

EXP_DIR=$REPO_DIR/experiments/vector_reduction/$EXPERIMENT_ID
pushd $REPO_DIR

# always update and overwrite the code dir
git pull
cp -r code/starpu/vector-reduction $EXP_DIR/code

for name in $PARTITIONS; do
    nodes=$(gppd-info --long --Node -S NODELIST -p $name -h | awk '{print $1 "_" $5}' | paste -s -d" " -)

    for execution in $nodes; do
        # launch the slurm script for this node
        sbatch \
            -p ${execution%%[0-9]*} \
            -w ${execution%%_*} \
            -c ${execution#*_} \
            -J ${EXPERIMENT_ID}_${execution}_${USER} \
            $EXP_DIR/exp.slurm $EXPERIMENT_ID $EXP_DIR
    done
done

popd
#+end_src

Which is to be used in the following way:

#+begin_src bash :tangle no
chmod +x launch.sh

./lauch.sh <experiment_id> <path_to_repo>
#+end_src

The maximum value for each element will be:

#+name: max_val
#+begin_src bash :tangle no :results value :exports results
echo 100
#+end_src

#+RESULTS: max_val
: 100

* Table of contents                                                   :TOC_3:
- [[#1---the-basics][1 - The basics]]
  - [[#design][Design]]
  - [[#script][Script]]
- [[#2---comparing-extra-implementations][2 - Comparing extra implementations]]
  - [[#design-1][Design]]
  - [[#script-1][Script]]

* 1 - The basics                                                      :EXP01:

It exists so I learn how to do stuff using R and slurm and shell scripts.

** Design

The random seed will be:

#+begin_src R :session :results value :exports results
floor(runif(1,1,99999))
#+end_src

#+RESULTS:
: 60485

Now the executions plan:

#+begin_src R :session :results none
size = c(70000000, 300000000, 1100000000)
nb = c(7000, 25000, 82000)
fr = c(2, 10, 1000)

fac.design(
    nfactors=3,
    replications=30,
    repeat.only=FALSE,
    blocks=1,
    randomize=TRUE,
    seed=60485,
    factor.names=list(
      vec_size=size,
      num_blocks=nb,
      reduction_factor=fr)) %>%
  as_tibble %>%
  transmute(id=as.numeric(Blocks), vec_size, num_blocks, reduction_factor) %>%
  write_delim("exp01/runs.plan", delim=" ", col_names=FALSE)

# the space delimited file is to help with the posterior parsing in the shell
# script
#+end_src


** Script

#+begin_src bash :shebang "#!/bin/bash" :tangle exp01/exp.slurm
#SBATCH --time=72:00:00
#SBATCH --workdir=.
#SBATCH --output=/home/users/hcpsilva/slurm_outputs/%x_%j.out
#SBATCH --error=/home/users/hcpsilva/slurm_outputs/%x_%j.err
#SBATCH --mail-type=END,FAIL
#SBATCH --mail-user=hcpsilva@inf.ufrgs.br

# parameters
# the experiment ID, defined in the lab-book
EXP_ID=$1
# the experiment directory
EXP_DIR=$2

# as defined in the experiment design
MAX_VALUE=100

# experiment name (which is the ID and the machine and its core count)
EXP_NAME=${EXP_ID}_${HOST}_${SLURM_CPUS_ON_NODE}

# go to the scratch dir to execute our operations
cd $SCRATCH

# clean up my scratch dir
rm -rf $SCRATCH/*

# install spack
git clone https://github.com/spack/spack.git
# source spack env variables
. spack/share/spack/setup-env.sh
# add the solverstack INRIA repo
git clone https://gitlab.inria.fr/solverstack/spack-repo.git solverstack
# and add it to spack
spack repo add solverstack

# install starpu and cia
spack install starpu@develop+fxt+poti~examples~mpi~openmp
echo "StarPU installed!"

# create install dir and put StarPU in it
mkdir install
spack view soft install starpu

STARPU_PATH=$(readlink -f install)

# set up path and ld path
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$STARPU_PATH/lib
export PATH=$PATH:$STARPU_PATH/bin
export PKG_CONFIG_PATH=$PKG_CONFIG_PATH:$STARPU_PATH/lib/pkgconfig

# prepare our directory
mkdir $EXP_NAME
pushd $EXP_NAME

# copy the code folder
cp -r $EXP_DIR/code code
mkdir results

# compile
pushd code
make
popd

# init the results csv
results_csv=results/${HOST}_data.csv
echo "node,rep_id,vector_size,num_blocks,reduc_fac,compute_time" > $results_csv

# execute the program
while read -r id vector_size num_blocks reduc_fac; do
    echo "-> Parameters set to: $vector_size $num_blocks $reduc_fac"

    # execute with given configurations
    c_time=$(./code/build/starpu $vector_size $num_blocks $reduc_fac $MAX_VALUE)

    # add execution data to csv
    echo ${HOST},${id},${vector_size},${num_blocks},${reduc_fac},${c_time} >> $results_csv

    # stress the memory to prevent cache influence between runs
    stress-ng --vm 3 --vm-bytes 75% -t 5s &> /dev/null

    echo
done < $EXP_DIR/runs.plan

# zip everything and commit to EXP_DIR
tar czf $EXP_DIR/${EXP_NAME}_data.tar.gz *

popd
rm -rf $SCRATCH/*
#+end_src

* 2 - Comparing extra implementations                                 :EXP02:

Because it's never enough.

** Design

The random seed will be:

#+begin_src R :session :results value :exports results
floor(runif(1,1,99999))
#+end_src

#+RESULTS:
: 95099

And the execution plan (same sizes as before):

#+begin_src R :session :results none
size = c(70000000, 300000000, 1100000000)
ver= c("naive", "cpp_reduce", "cpp_accumulate", "openmp")

fac.design(
    nfactors=2,
    replications=30,
    repeat.only=FALSE,
    blocks=1,
    randomize=TRUE,
    seed=95099,
    factor.names=list(
      vec_size=size,
      version=ver)) %>%
  as_tibble %>%
  transmute(id=as.numeric(Blocks), version, vec_size) %>%
  write_delim("exp02/runs.plan", delim=" ", col_names=FALSE)

# the space delimited file is to help with the posterior parsing in the shell
# script
#+end_src

** Script

#+begin_src bash :shebang "#!/bin/bash" :tangle exp02/exp.slurm
#SBATCH --time=72:00:00
#SBATCH --workdir=.
#SBATCH --output=/home/users/hcpsilva/slurm_outputs/%x_%j.out
#SBATCH --error=/home/users/hcpsilva/slurm_outputs/%x_%j.err
#SBATCH --mail-type=END,FAIL
#SBATCH --mail-user=hcpsilva@inf.ufrgs.br

# parameters
# the experiment ID, defined in the lab-book
EXP_ID=$1
# the experiment directory
EXP_DIR=$2

# as defined in the experiment design
MAX_VALUE=100

# experiment name (which is the ID and the machine and its core count)
EXP_NAME=${EXP_ID}_${HOST}_${SLURM_CPUS_ON_NODE}

# go to the scratch dir to execute our operations
cd $SCRATCH

# clean up my scratch dir
rm -rf $SCRATCH/*

# install spack
git clone https://github.com/spack/spack.git
# source spack env variables
. spack/share/spack/setup-env.sh
# add the solverstack INRIA repo
git clone https://gitlab.inria.fr/solverstack/spack-repo.git solverstack
# and add it to spack
spack repo add solverstack

# install starpu and cia
spack install starpu@develop+fxt+poti~examples~mpi~openmp
echo "StarPU installed!"

# create install dir and put StarPU in it
mkdir install
spack view soft install starpu

STARPU_PATH=$(readlink -f install)

# set up path and ld path
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$STARPU_PATH/lib
export PATH=$PATH:$STARPU_PATH/bin
export PKG_CONFIG_PATH=$PKG_CONFIG_PATH:$STARPU_PATH/lib/pkgconfig

# prepare our directory
mkdir $EXP_NAME
pushd $EXP_NAME

# copy the code folder
cp -r $EXP_DIR/code code
mkdir results

# compile
pushd code
make
popd

# init the results csv
results_csv=results/${HOST}_data.csv
echo "node,rep_id,version,vector_size,compute_time" > $results_csv

# execute the program
while read -r id version vector_size; do
    echo "-> Parameters set to: $version $vector_size"

    # execute with given configurations
    c_time=$(./code/build/$version $vector_size $MAX_VALUE)

    # add execution data to csv
    echo ${HOST},${id},${version},${vector_size},${c_time} >> $results_csv

    # stress the memory to prevent cache influence between runs
    stress-ng --vm 3 --vm-bytes 75% -t 5s &> /dev/null

    echo
done < $EXP_DIR/runs.plan

# zip everything and commit to EXP_DIR
tar czf $EXP_DIR/${EXP_NAME}_data.tar.gz *

popd
rm -rf $SCRATCH/*
#+end_src
