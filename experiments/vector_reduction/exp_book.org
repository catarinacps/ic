#+title: Vector Reduction Experiments book
#+author: Henrique Silva
#+email: hcpsilva@inf.ufrgs.br
#+infojs_opt:
#+property: session *R*
#+property: cache yes
#+property: results graphics
#+property: exports both
#+property: tangle yes

It reduces a vector, that's it.

Preliminary library loading:

#+begin_src R :session :results none
library(DoE.base)
library(tidyverse)
#+end_src

And the partitions intended to be used in this test:

#+name: machines
#+begin_src bash :tangle no
echo "draco hype knl orion tupi"
#+end_src

And the scheduling of experiments is supposed to happen according to this
script (which is, by the way, surprisingly generic):

#+begin_src bash :shebang "#!/bin/bash" :tangle launch.sh :var PARTITIONS=machines
# the experiment id
EXPERIMENT_ID=${@[0]}

# the work (repo) dir
REPO_DIR="$HOME/ic"
EXP_DIR="$REPODIR/experiments/vector_reduction/$EXPERIMENT_ID"
pushd $REPODIR

if [ ! -d "$EXP_DIR/code" ]; then
    git pull
    cp -r code/starpu/vector-reduction $EXP_DIR/code
fi

# to keep track on IDs
job_id=0

for name in "$PARTITIONS"; do
    nodes=$(gppd-info --long --Node -S NODELIST -p $name -h | awk '{print $1 "_" $7}' | paste -s -d" " -)

    for execution in "$nodes"; do
        # launch the slurm script for this node
        sbatch -w ${execution%%_*} $EXPERIMENT_ID/exp.slurm $execution $job_id $EXP_DIR

        # increment execution id
        ((job_id++))
    done
done
#+end_src

Which is to be used in the following way:

#+begin_src bash :tangle no
chmod +x launch.sh

./lauch.sh <experiment_id>
#+end_src

* Table of contents                                                   :TOC_3:
- [[#1---the-basics][1 - The basics]]
  - [[#experiment-plan][Experiment plan]]
  - [[#slurm-script][Slurm script]]

* 1 - The basics                                                      :EXP01:

It exists so I learn how to do stuff using R and slurm and shell scripts.

** Experiment plan

#+begin_src R :session :results none
size = c("70000000", "300000000", "1100000000")
nb = c("7000", "25000", "82000")
fr = c("2", "10", "1000")

fac.design (
    nfactors=3,
    replications=10,
    repeat.only=FALSE,
    blocks=1,
    randomize=TRUE,
    seed=10373,
    factor.names=list(
        Size=size,
        NumberOfBlocks=nb,
        ReductionFactor=fr)) %>%
  as_tibble %>%
  select(-Blocks) %>%
  write_delim("exp01/runs.plan", delim=" ", col_names=FALSE)

# the space delimited file is to help with the posterior parsing in the shell
# script
#+end_src

** Slurm script

#+begin_src bash :tangle exp01/exp.slurm
#!/bin/bash
#SBATCH --time=02:00:00
#SBATCH --workdir=.
#SBATCH --output=%x_%j.out
#SBATCH --error=%x_%j.err

# parameters
EXEC_NAME=${@[0]}
EXEC_ID=${@[1]}
EXP_DIR=${@[2]}

# prepare the machine file
MACHINEFILE="nodes.$SLURM_JOB_ID.$EXEC_NAME.$EXEC_ID"

# source spack env variables
source $HOME/Repositories/spack/share/spack/setup-env.sh

# prepare our directory
pushd $SCRATCH
mkdir $EXEC_NAME
pushd $EXEC_NAME

# copy the code folder
cp -r $EXP_DIR/code code/

# compile
cd code/
[ ! -d build/ ] && mkdir build/
cd build/
cmake -DSTARPU_DIR=$(spack location -i starpu) ..
cmake -DSTARPU_DIR=$(spack location -i starpu) ..
make

# execute the program
while read config; do
    echo "-> Parameters set to: $config"
    echo
    ../bin/vector-reduction ${config[0]} ${config[1]} ${config[2]}
    echo
done <$EXP_DIR/runs.plan

popd
rm -rf $EXEC_NAME
#+end_src
